Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
config:
dataset : celeba
batch_size : 128
image_size : 64
num_epochs : 5
data_path : data/celeba
workers : 8
print_every : 200
save_every : 500
manual_seed : 999
train_load_check_point_file : False
number_channels : 3
size_of_z_latent : 100
number_gpus : 1
number_of_generator_feature : 64
number_of_discriminator_feature : 64
learn_rate : 0.0002
beta1 : 0.5
real_label : 1
fake_label : 0
loss_rate : 0.5
lan : 0.01
device : cpu
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
config:
dataset : celeba
batch_size : 128
image_size : 64
num_epochs : 5
data_path : data/celeba
workers : 8
print_every : 200
save_every : 500
manual_seed : 999
train_load_check_point_file : False
number_channels : 3
size_of_z_latent : 100
number_gpus : 1
number_of_generator_feature : 64
number_of_discriminator_feature : 64
learn_rate : 0.0002
beta1 : 0.5
real_label : 1
fake_label : 0
loss_rate : 0.5
lan : 0.01
device : cpu
[0/5]	[0/1583]	 Loss_D: 1.0579	 Loss_G: 2.4306	 D(x): 0.2745	 D(G(z)): 0.3527 / 0.1157 take_time: 15s
[0/5]	[200/1583]	 Loss_D: 0.1960	 Loss_G: 5.5735	 D(x): 0.7938	 D(G(z)): 0.0565 / 0.0057 take_time: 2526s
[0/5]	[400/1583]	 Loss_D: 0.2448	 Loss_G: 3.6933	 D(x): 0.7945	 D(G(z)): 0.1509 / 0.0363 take_time: 4905s
[0/5]	[600/1583]	 Loss_D: 0.6436	 Loss_G: 3.4816	 D(x): 0.4471	 D(G(z)): 0.0059 / 0.0649 take_time: 7132s
[0/5]	[800/1583]	 Loss_D: 0.4099	 Loss_G: 9.9101	 D(x): 0.9529	 D(G(z)): 0.4645 / 0.0001 take_time: 9211s
[0/5]	[1000/1583]	 Loss_D: 0.0950	 Loss_G: 5.0655	 D(x): 0.9120	 D(G(z)): 0.0797 / 0.0103 take_time: 11278s
[0/5]	[1200/1583]	 Loss_D: 0.3547	 Loss_G: 7.7484	 D(x): 0.9355	 D(G(z)): 0.3930 / 0.0011 take_time: 13347s
[0/5]	[1400/1583]	 Loss_D: 0.3466	 Loss_G: 5.3809	 D(x): 0.8074	 D(G(z)): 0.3168 / 0.0080 take_time: 15455s
[1/5]	[0/1583]	 Loss_D: 0.2194	 Loss_G: 3.5861	 D(x): 0.7150	 D(G(z)): 0.0324 / 0.0446 take_time: 17598s
[1/5]	[200/1583]	 Loss_D: 0.8973	 Loss_G: 0.8537	 D(x): 0.2497	 D(G(z)): 0.0039 / 0.5472 take_time: 20108s
[1/5]	[400/1583]	 Loss_D: 0.1250	 Loss_G: 3.0577	 D(x): 0.9040	 D(G(z)): 0.1184 / 0.0822 take_time: 22583s
[1/5]	[600/1583]	 Loss_D: 0.1781	 Loss_G: 2.8075	 D(x): 0.8025	 D(G(z)): 0.0949 / 0.0946 take_time: 24805s
[1/5]	[800/1583]	 Loss_D: 0.2580	 Loss_G: 2.9548	 D(x): 0.6783	 D(G(z)): 0.0366 / 0.0918 take_time: 26902s
[1/5]	[1000/1583]	 Loss_D: 0.3599	 Loss_G: 2.9060	 D(x): 0.5867	 D(G(z)): 0.0346 / 0.0898 take_time: 29057s
[1/5]	[1200/1583]	 Loss_D: 0.2116	 Loss_G: 3.7396	 D(x): 0.8816	 D(G(z)): 0.2310 / 0.0333 take_time: 31222s
[1/5]	[1400/1583]	 Loss_D: 0.3340	 Loss_G: 2.2575	 D(x): 0.6945	 D(G(z)): 0.1963 / 0.1494 take_time: 33331s
[2/5]	[0/1583]	 Loss_D: 0.3905	 Loss_G: 5.5445	 D(x): 0.9755	 D(G(z)): 0.4848 / 0.0066 take_time: 35246s
[2/5]	[200/1583]	 Loss_D: 0.3185	 Loss_G: 3.8075	 D(x): 0.8797	 D(G(z)): 0.3558 / 0.0344 take_time: 37399s
[2/5]	[400/1583]	 Loss_D: 0.4707	 Loss_G: 4.9184	 D(x): 0.8983	 D(G(z)): 0.5077 / 0.0140 take_time: 39498s
[2/5]	[600/1583]	 Loss_D: 0.4425	 Loss_G: 1.0793	 D(x): 0.5353	 D(G(z)): 0.1350 / 0.3872 take_time: 41581s
[2/5]	[800/1583]	 Loss_D: 0.3688	 Loss_G: 2.1887	 D(x): 0.7831	 D(G(z)): 0.3467 / 0.1404 take_time: 43720s
[2/5]	[1000/1583]	 Loss_D: 0.3291	 Loss_G: 3.6318	 D(x): 0.9129	 D(G(z)): 0.3866 / 0.0377 take_time: 46241s
[2/5]	[1200/1583]	 Loss_D: 0.3370	 Loss_G: 2.6522	 D(x): 0.8467	 D(G(z)): 0.3543 / 0.0897 take_time: 48365s
[2/5]	[1400/1583]	 Loss_D: 0.5902	 Loss_G: 4.5107	 D(x): 0.9467	 D(G(z)): 0.6152 / 0.0185 take_time: 50459s
[3/5]	[0/1583]	 Loss_D: 0.4586	 Loss_G: 3.1612	 D(x): 0.8285	 D(G(z)): 0.4507 / 0.0611 take_time: 52378s
[3/5]	[200/1583]	 Loss_D: 0.1739	 Loss_G: 2.8712	 D(x): 0.8434	 D(G(z)): 0.1416 / 0.0763 take_time: 54499s
[3/5]	[400/1583]	 Loss_D: 0.3764	 Loss_G: 4.1126	 D(x): 0.8929	 D(G(z)): 0.4278 / 0.0285 take_time: 56583s
[3/5]	[600/1583]	 Loss_D: 0.2984	 Loss_G: 2.3640	 D(x): 0.8025	 D(G(z)): 0.2665 / 0.1221 take_time: 58645s
[3/5]	[800/1583]	 Loss_D: 0.3646	 Loss_G: 2.3389	 D(x): 0.7301	 D(G(z)): 0.2680 / 0.1251 take_time: 60695s
[3/5]	[1000/1583]	 Loss_D: 0.2801	 Loss_G: 2.7716	 D(x): 0.8240	 D(G(z)): 0.2733 / 0.0843 take_time: 62739s
[3/5]	[1200/1583]	 Loss_D: 0.5775	 Loss_G: 0.6108	 D(x): 0.3994	 D(G(z)): 0.0685 / 0.5846 take_time: 64785s
[3/5]	[1400/1583]	 Loss_D: 0.7686	 Loss_G: 0.3015	 D(x): 0.2751	 D(G(z)): 0.0227 / 0.7749 take_time: 66881s
[4/5]	[0/1583]	 Loss_D: 0.3710	 Loss_G: 3.7523	 D(x): 0.8903	 D(G(z)): 0.4090 / 0.0356 take_time: 68820s
[4/5]	[200/1583]	 Loss_D: 0.3550	 Loss_G: 2.6136	 D(x): 0.7466	 D(G(z)): 0.2855 / 0.0961 take_time: 70942s
[4/5]	[400/1583]	 Loss_D: 0.3075	 Loss_G: 1.6430	 D(x): 0.6836	 D(G(z)): 0.1704 / 0.2291 take_time: 73029s
[4/5]	[600/1583]	 Loss_D: 0.2676	 Loss_G: 1.7583	 D(x): 0.6802	 D(G(z)): 0.0900 / 0.2166 take_time: 75096s
[4/5]	[800/1583]	 Loss_D: 0.3549	 Loss_G: 1.5103	 D(x): 0.5796	 D(G(z)): 0.0832 / 0.2661 take_time: 77163s
[4/5]	[1000/1583]	 Loss_D: 0.2561	 Loss_G: 3.1592	 D(x): 0.8937	 D(G(z)): 0.3036 / 0.0532 take_time: 79218s
[4/5]	[1200/1583]	 Loss_D: 0.2932	 Loss_G: 3.0268	 D(x): 0.8533	 D(G(z)): 0.3166 / 0.0621 take_time: 81260s
[4/5]	[1400/1583]	 Loss_D: 0.3482	 Loss_G: 1.8518	 D(x): 0.6271	 D(G(z)): 0.1238 / 0.1965 take_time: 83309s
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
config:
dataset : celeba
batch_size : 128
image_size : 64
num_epochs : 1
data_path : data/celeba
workers : 8
print_every : 200
save_every : 500
manual_seed : 999
train_load_check_point_file : False
number_channels : 3
size_of_z_latent : 100
number_gpus : 1
number_of_generator_feature : 64
number_of_discriminator_feature : 64
learn_rate : 0.0002
beta1 : 0.5
real_label : 1
fake_label : 0
loss_rate : 0.5
lan : 0.01
device : cpu
[0/1]	[0/1583]	 Loss_D: 1.0118	 Loss_G: 2.1760	 D(x): 0.2649	 D(G(z)): 0.3197 / 0.1440 take_time: 18s
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
config:
dataset : celeba
batch_size : 128
image_size : 64
num_epochs : 1
data_path : data/celeba
workers : 8
print_every : 200
save_every : 500
manual_seed : 999
train_load_check_point_file : False
number_channels : 3
size_of_z_latent : 100
number_gpus : 1
number_of_generator_feature : 64
number_of_discriminator_feature : 64
learn_rate : 0.0002
beta1 : 0.5
real_label : 1
fake_label : 0
loss_rate : 0.5
lan : 0.01
device : cpu
[0/1]	[0/1583]	 Loss_D: 1.0118	 Loss_G: 2.1760	 D(x): 0.2649	 D(G(z)): 0.3197 / 0.1440 take_time: 15s
[0/1]	[200/1583]	 Loss_D: 0.1855	 Loss_G: 4.1906	 D(x): 0.8463	 D(G(z)): 0.1441 / 0.0223 take_time: 2199s
[0/1]	[400/1583]	 Loss_D: 0.1251	 Loss_G: 5.9470	 D(x): 0.8825	 D(G(z)): 0.0628 / 0.0071 take_time: 4323s
[0/1]	[600/1583]	 Loss_D: 0.2854	 Loss_G: 4.1718	 D(x): 0.7512	 D(G(z)): 0.1880 / 0.0244 take_time: 6513s
[0/1]	[800/1583]	 Loss_D: 0.1564	 Loss_G: 4.1348	 D(x): 0.8620	 D(G(z)): 0.1169 / 0.0287 take_time: 8951s
[0/1]	[1000/1583]	 Loss_D: 0.1726	 Loss_G: 5.0575	 D(x): 0.8097	 D(G(z)): 0.0610 / 0.0150 take_time: 11599s
[0/1]	[1200/1583]	 Loss_D: 0.2967	 Loss_G: 3.9480	 D(x): 0.8324	 D(G(z)): 0.2663 / 0.0411 take_time: 14051s
[0/1]	[1400/1583]	 Loss_D: 0.3996	 Loss_G: 6.8361	 D(x): 0.9190	 D(G(z)): 0.4265 / 0.0034 take_time: 16436s
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
config:
dataset : celeba
batch_size : 128
image_size : 64
num_epochs : 5
data_path : data/celeba
workers : 8
print_every : 200
save_every : 500
manual_seed : 999
train_load_check_point_file : False
number_channels : 3
size_of_z_latent : 100
number_gpus : 1
number_of_generator_feature : 64
number_of_discriminator_feature : 64
learn_rate : 0.0002
beta1 : 0.5
real_label : 1
fake_label : 0
loss_rate : 0.5
lan : 2
device : cpu
[0/5]	[0/1583]	 Loss_D: 1.0472	 Loss_G: 2.0463	 D(x): 0.2533	 D(G(z)): 0.3110 / 0.1664 take_time: 15s
[0/5]	[200/1583]	 Loss_D: 0.2354	 Loss_G: 6.3863	 D(x): 0.8941	 D(G(z)): 0.2675 / 0.0030 take_time: 2409s
[0/5]	[400/1583]	 Loss_D: 0.2647	 Loss_G: 6.0047	 D(x): 0.8313	 D(G(z)): 0.2211 / 0.0076 take_time: 4531s
[0/5]	[600/1583]	 Loss_D: 0.1665	 Loss_G: 3.9196	 D(x): 0.8902	 D(G(z)): 0.1540 / 0.0337 take_time: 6634s
[0/5]	[800/1583]	 Loss_D: 0.3798	 Loss_G: 3.9202	 D(x): 0.5609	 D(G(z)): 0.0130 / 0.0415 take_time: 8732s
[0/5]	[1000/1583]	 Loss_D: 0.8280	 Loss_G: 3.9876	 D(x): 0.3314	 D(G(z)): 0.0044 / 0.0360 take_time: 10822s
[0/5]	[1200/1583]	 Loss_D: 1.2535	 Loss_G: 2.6862	 D(x): 0.1787	 D(G(z)): 0.0032 / 0.1151 take_time: 12930s
[0/5]	[1400/1583]	 Loss_D: 0.4863	 Loss_G: 8.1938	 D(x): 0.9274	 D(G(z)): 0.5243 / 0.0005 take_time: 15005s
[1/5]	[0/1583]	 Loss_D: 0.2733	 Loss_G: 4.5288	 D(x): 0.8781	 D(G(z)): 0.2864 / 0.0219 take_time: 16901s
[1/5]	[200/1583]	 Loss_D: 0.2525	 Loss_G: 2.9367	 D(x): 0.7883	 D(G(z)): 0.1726 / 0.0904 take_time: 19013s
[1/5]	[400/1583]	 Loss_D: 0.1815	 Loss_G: 4.8598	 D(x): 0.9241	 D(G(z)): 0.2212 / 0.0123 take_time: 21099s
[1/5]	[600/1583]	 Loss_D: 0.8359	 Loss_G: 7.3982	 D(x): 0.9643	 D(G(z)): 0.7224 / 0.0013 take_time: 23171s
[1/5]	[800/1583]	 Loss_D: 0.2274	 Loss_G: 2.6522	 D(x): 0.7682	 D(G(z)): 0.1230 / 0.0945 take_time: 25237s
[1/5]	[1000/1583]	 Loss_D: 0.4189	 Loss_G: 2.6568	 D(x): 0.6554	 D(G(z)): 0.2310 / 0.1099 take_time: 27306s
[1/5]	[1200/1583]	 Loss_D: 0.1746	 Loss_G: 3.2643	 D(x): 0.7856	 D(G(z)): 0.0625 / 0.0544 take_time: 29373s
[1/5]	[1400/1583]	 Loss_D: 0.2305	 Loss_G: 3.2767	 D(x): 0.7288	 D(G(z)): 0.0817 / 0.0601 take_time: 31446s
[2/5]	[0/1583]	 Loss_D: 0.3789	 Loss_G: 4.2992	 D(x): 0.9270	 D(G(z)): 0.4449 / 0.0228 take_time: 33364s
[2/5]	[200/1583]	 Loss_D: 0.2411	 Loss_G: 3.6975	 D(x): 0.8472	 D(G(z)): 0.2426 / 0.0357 take_time: 36027s
[2/5]	[400/1583]	 Loss_D: 0.9324	 Loss_G: 5.5288	 D(x): 0.9561	 D(G(z)): 0.7680 / 0.0091 take_time: 38261s
[2/5]	[600/1583]	 Loss_D: 0.5552	 Loss_G: 0.9733	 D(x): 0.4131	 D(G(z)): 0.0609 / 0.4393 take_time: 40395s
[2/5]	[800/1583]	 Loss_D: 0.5280	 Loss_G: 1.5953	 D(x): 0.7052	 D(G(z)): 0.3901 / 0.2820 take_time: 42527s
[2/5]	[1000/1583]	 Loss_D: 0.2871	 Loss_G: 3.2284	 D(x): 0.8372	 D(G(z)): 0.2838 / 0.0545 take_time: 44638s
[2/5]	[1200/1583]	 Loss_D: 0.2471	 Loss_G: 1.9995	 D(x): 0.7499	 D(G(z)): 0.1385 / 0.1706 take_time: 47008s
[2/5]	[1400/1583]	 Loss_D: 0.2477	 Loss_G: 2.1403	 D(x): 0.7792	 D(G(z)): 0.1869 / 0.1469 take_time: 49421s
[3/5]	[0/1583]	 Loss_D: 0.2947	 Loss_G: 3.4394	 D(x): 0.8764	 D(G(z)): 0.3299 / 0.0405 take_time: 51382s
[3/5]	[200/1583]	 Loss_D: 0.3100	 Loss_G: 2.3124	 D(x): 0.7973	 D(G(z)): 0.2843 / 0.1260 take_time: 53585s
[3/5]	[400/1583]	 Loss_D: 0.2729	 Loss_G: 3.0144	 D(x): 0.8716	 D(G(z)): 0.3035 / 0.0628 take_time: 56147s
[3/5]	[600/1583]	 Loss_D: 0.3521	 Loss_G: 4.0800	 D(x): 0.9467	 D(G(z)): 0.4415 / 0.0263 take_time: 58541s
[3/5]	[800/1583]	 Loss_D: 0.3284	 Loss_G: 1.5428	 D(x): 0.6375	 D(G(z)): 0.1302 / 0.2536 take_time: 60689s
[3/5]	[1000/1583]	 Loss_D: 0.5376	 Loss_G: 3.9574	 D(x): 0.9238	 D(G(z)): 0.5711 / 0.0402 take_time: 63014s
[3/5]	[1200/1583]	 Loss_D: 0.7487	 Loss_G: 6.3056	 D(x): 0.9612	 D(G(z)): 0.7198 / 0.0031 take_time: 65203s
[3/5]	[1400/1583]	 Loss_D: 0.3023	 Loss_G: 2.3552	 D(x): 0.7503	 D(G(z)): 0.2403 / 0.1143 take_time: 67595s
[4/5]	[0/1583]	 Loss_D: 0.2866	 Loss_G: 2.5950	 D(x): 0.7901	 D(G(z)): 0.2573 / 0.0941 take_time: 69622s
[4/5]	[200/1583]	 Loss_D: 0.2139	 Loss_G: 1.8992	 D(x): 0.7424	 D(G(z)): 0.0874 / 0.1758 take_time: 71797s
[4/5]	[400/1583]	 Loss_D: 0.2652	 Loss_G: 2.9763	 D(x): 0.8689	 D(G(z)): 0.2925 / 0.0668 take_time: 73918s
[4/5]	[600/1583]	 Loss_D: 0.8853	 Loss_G: 4.0767	 D(x): 0.8826	 D(G(z)): 0.7309 / 0.0283 take_time: 76048s
[4/5]	[800/1583]	 Loss_D: 0.3111	 Loss_G: 1.3240	 D(x): 0.6468	 D(G(z)): 0.1255 / 0.3028 take_time: 78155s
[4/5]	[1000/1583]	 Loss_D: 0.2129	 Loss_G: 2.9125	 D(x): 0.8657	 D(G(z)): 0.2211 / 0.0720 take_time: 80227s
[4/5]	[1200/1583]	 Loss_D: 0.3508	 Loss_G: 2.9453	 D(x): 0.9059	 D(G(z)): 0.4049 / 0.0751 take_time: 82289s
[4/5]	[1400/1583]	 Loss_D: 0.2933	 Loss_G: 1.7967	 D(x): 0.6799	 D(G(z)): 0.1244 / 0.2076 take_time: 84363s
